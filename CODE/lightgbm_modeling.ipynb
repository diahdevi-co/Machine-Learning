{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EFP47QJmLXt"
      },
      "source": [
        "# 1. SETTINGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M9mo4JPcmLXw"
      },
      "outputs": [],
      "source": [
        "# libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import lightgbm as lgb\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChNGVDWqmLXz"
      },
      "outputs": [],
      "source": [
        "# garbage collection\n",
        "import gc\n",
        "gc.enable()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBjSkhxBmLX1"
      },
      "outputs": [],
      "source": [
        "# pandas options\n",
        "pd.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqcFwiVUmLX2"
      },
      "outputs": [],
      "source": [
        "# ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR7rRkWFmLX3"
      },
      "outputs": [],
      "source": [
        "# random settings\n",
        "seed = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0Aj3unKmLX4"
      },
      "source": [
        "# 2. PREPARATIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoqJyxXDmLX6"
      },
      "outputs": [],
      "source": [
        "# dataset\n",
        "data = \"v1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sg2X4x8OmLX7"
      },
      "outputs": [],
      "source": [
        "# import data\n",
        "train_features_df = pd.read_csv(\"/content/train_features (1).csv\")\n",
        "test  = pd.read_csv(\"/content/test_features.csv\")\n",
        "train_labels_df = pd.read_csv(\"/content/train_labels (2).csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2q19U1WmLX8"
      },
      "outputs": [],
      "source": [
        "# Merge train features and labels on SK_ID_CURR to ensure alignment\n",
        "train = pd.merge(train_features_df, train_labels_df, on=\"SK_ID_CURR\", how=\"inner\")\n",
        "\n",
        "# Sort data\n",
        "train = train.sort_values(\"SK_ID_CURR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rl3KpNSmLX9"
      },
      "outputs": [],
      "source": [
        "# extract target\n",
        "y = train[\"TARGET\"]\n",
        "train = train.drop(columns=[\"TARGET\"]) # Remove TARGET from features in train dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvvaRM6PmLX9"
      },
      "outputs": [],
      "source": [
        "# exclude features\n",
        "excluded_feats = [\"SK_ID_CURR\"]\n",
        "\n",
        "# Get common columns between train and test\n",
        "common_cols = list(set(train.columns) & set(test.columns))\n",
        "\n",
        "# Clean feature names to remove problematic characters for LightGBM\n",
        "import re\n",
        "def clean_feature_names(features_list):\n",
        "    cleaned_features = []\n",
        "    for feature in features_list:\n",
        "        # Replace problematic characters with underscore using regex\n",
        "        cleaned_feature = re.sub(r'[^A-Za-z0-9_]+', '_', feature)\n",
        "        # Further clean by stripping leading/trailing underscores and collapsing multiple underscores\n",
        "        cleaned_feature = cleaned_feature.strip('_')\n",
        "        cleaned_feature = re.sub(r'__+', '_', cleaned_feature)\n",
        "        cleaned_features.append(cleaned_feature)\n",
        "    return cleaned_features\n",
        "\n",
        "features = [f for f in common_cols if f not in excluded_feats]\n",
        "features = clean_feature_names(features)\n",
        "\n",
        "# Apply cleaning to the actual dataframe columns as well\n",
        "train.columns = clean_feature_names(train.columns)\n",
        "test.columns = clean_feature_names(test.columns)\n",
        "\n",
        "# Re-filter features after cleaning, in case some features were renamed\n",
        "features = [f for f in features if f in train.columns and f in test.columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eW8PpDJMmLX-"
      },
      "outputs": [],
      "source": [
        "# check dimensions\n",
        "print(train[features].shape)\n",
        "print(test[features].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U46sWqX4mLX_"
      },
      "outputs": [],
      "source": [
        "### PARAMETERS\n",
        "\n",
        "# parallel settings\n",
        "cores = 10\n",
        "\n",
        "# learner settings\n",
        "metric   = \"auc\"\n",
        "verbose  = 500\n",
        "stopping = 300\n",
        "\n",
        "# CV settings\n",
        "num_folds = 5\n",
        "shuffle   = True\n",
        "\n",
        "# lightGBM\n",
        "gbm = lgb.LGBMClassifier(n_estimators     = 10000,\n",
        "                         learning_rate    = 0.005,\n",
        "                         num_leaves       = 31,\n",
        "                         colsample_bytree = 0.8,\n",
        "                         subsample        = 0.9,\n",
        "                         max_depth        = 5,\n",
        "                         reg_alpha        = 0.1,\n",
        "                         reg_lambda       = 0.1,\n",
        "                         min_split_gain   = 0.2,  # Increased\n",
        "                         min_child_weight = 5,    # Increased\n",
        "                         random_state     = seed,\n",
        "                         num_threads      = cores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJAAUQ8UmLX_"
      },
      "source": [
        "# 3. CROSS-VALIDATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7-Gt4RNmLYA"
      },
      "source": [
        "## 3.1. ALL FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEd08yNBmLYA"
      },
      "outputs": [],
      "source": [
        "# Convert object columns to float in both train and test dataframes\n",
        "for col in features:\n",
        "    if train[col].dtype == 'object':\n",
        "        # Convert boolean-like strings to numeric before casting to float\n",
        "        train[col] = (\n",
        "            train[col]\n",
        "            .replace({'True': 1.0, 'False': 0.0, 'F': 0.0, 'T': 1.0})\n",
        "            .astype(float, errors='ignore')\n",
        "        )\n",
        "        train[col] = pd.to_numeric(train[col], errors='coerce').fillna(0)\n",
        "\n",
        "    if test[col].dtype == 'object':\n",
        "        # Convert boolean-like strings to numeric before casting to float\n",
        "        test[col] = (\n",
        "            test[col]\n",
        "            .replace({'True': 1.0, 'False': 0.0, 'F': 0.0, 'T': 1.0})\n",
        "            .astype(float, errors='ignore')\n",
        "        )\n",
        "        test[col] = pd.to_numeric(test[col], errors='coerce').fillna(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "faFDvU9CmLYA"
      },
      "outputs": [],
      "source": [
        "# CV\n",
        "folds = StratifiedKFold(\n",
        "    n_splits=num_folds,\n",
        "    shuffle=True,\n",
        "    random_state=seed\n",
        ")\n",
        "\n",
        "valid_aucs_cv = np.zeros(num_folds)\n",
        "test_preds_cv = np.zeros(test.shape[0])\n",
        "feature_importance_df = pd.DataFrame()\n",
        "\n",
        "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y)):\n",
        "    print(f\"\\n========== Fold {n_fold + 1} ==========\")\n",
        "\n",
        "    # =========================\n",
        "    # Data partitioning\n",
        "    # =========================\n",
        "    trn_x = train[features].iloc[trn_idx]\n",
        "    trn_y = y.iloc[trn_idx]\n",
        "    val_x = train[features].iloc[val_idx]\n",
        "    val_y = y.iloc[val_idx]\n",
        "\n",
        "    # =========================\n",
        "    # Model (RE-INIT per fold)\n",
        "    # =========================\n",
        "    gbm = lgb.LGBMClassifier(\n",
        "        n_estimators=10000,\n",
        "        learning_rate=0.01,          # sedikit dinaikkan\n",
        "        num_leaves=63,               # diperbesar\n",
        "        max_depth=-1,                # biarkan tree berkembang\n",
        "        min_child_weight=1,          # dilonggarkan\n",
        "        min_split_gain=0.0,          # dilonggarkan\n",
        "        colsample_bytree=0.8,\n",
        "        subsample=0.8,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=0.1,\n",
        "        objective=\"binary\",\n",
        "        metric=\"auc\",\n",
        "        random_state=seed,\n",
        "        num_threads=cores,\n",
        "        force_col_wise=True          # hilangkan overhead\n",
        "    )\n",
        "\n",
        "    # =========================\n",
        "    # Training\n",
        "    # =========================\n",
        "    gbm.fit(\n",
        "        trn_x,\n",
        "        trn_y,\n",
        "        eval_set=[(val_x, val_y)],\n",
        "        eval_metric=\"auc\",\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(stopping_rounds=200),\n",
        "            lgb.log_evaluation(period=500)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # =========================\n",
        "    # Validation AUC\n",
        "    # =========================\n",
        "    val_pred = gbm.predict_proba(val_x)[:, 1]\n",
        "    valid_aucs_cv[n_fold] = roc_auc_score(val_y, val_pred)\n",
        "\n",
        "    print(f\"Fold {n_fold + 1} AUC: {valid_aucs_cv[n_fold]:.5f}\")\n",
        "\n",
        "    # =========================\n",
        "    # Test prediction (bagging)\n",
        "    # =========================\n",
        "    test_preds_cv += gbm.predict_proba(test[features])[:, 1] / num_folds\n",
        "\n",
        "    # =========================\n",
        "    # Feature importance\n",
        "    # =========================\n",
        "    fold_importance = pd.DataFrame({\n",
        "        \"Feature\": features,\n",
        "        \"Importance\": gbm.feature_importances_,\n",
        "        \"Fold\": n_fold + 1\n",
        "    })\n",
        "\n",
        "    feature_importance_df = pd.concat(\n",
        "        [feature_importance_df, fold_importance],\n",
        "        axis=0\n",
        "    )\n",
        "\n",
        "# =========================\n",
        "# CV summary\n",
        "# =========================\n",
        "print(\"\\n========== CV RESULT ==========\")\n",
        "print(f\"Mean AUC  : {valid_aucs_cv.mean():.6f}\")\n",
        "print(f\"Std  AUC  : {valid_aucs_cv.std():.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0ptb5h2mLYB"
      },
      "outputs": [],
      "source": [
        "##### VARIABLE IMPORTANCE\n",
        "\n",
        "# load importance\n",
        "top_feats = 50\n",
        "cols = feature_importance_df[[\"Feature\", \"Importance\"]].groupby(\"Feature\").mean().sort_values(by = \"Importance\", ascending = False)[0:top_feats].index\n",
        "importance = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
        "\n",
        "# plot variable importance\n",
        "plt.figure(figsize = (10, 10))\n",
        "sns.barplot(x = \"Importance\", y = \"Feature\", data = importance.sort_values(by = \"Importance\", ascending = False))\n",
        "plt.title('LightGBM Variable Importance (mean over CV folds)')\n",
        "plt.tight_layout()\n",
        "\n",
        "# save plot as pdf\n",
        "plt.savefig(\"../var_importance.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM5iIWpHmLYB"
      },
      "source": [
        "## 3.2. TOP FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhh_hUV8mLYB"
      },
      "outputs": [],
      "source": [
        "# keep top features\n",
        "top = 500\n",
        "cols = feature_importance_df[[\"Feature\", \"Importance\"]].groupby(\"Feature\").mean().sort_values(by = \"Importance\", ascending = False)[0:top].index\n",
        "importance = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
        "features = list(importance.groupby(\"Feature\").Importance.mean().sort_values(ascending = False).index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sYS6DqxmLYB"
      },
      "outputs": [],
      "source": [
        "# check dimensions\n",
        "print(train[features].shape)\n",
        "print(test[features].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "HB0IweAImLYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c31085f-6585-4112-f7e1-30471a605a62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== Fold 1 ==========\n",
            "[LightGBM] [Info] Number of positive: 789, number of negative: 9425\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.436518 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 94433\n",
            "[LightGBM] [Info] Number of data points in the train set: 10214, number of used features: 500\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077247 -> initscore=-2.480355\n",
            "[LightGBM] [Info] Start training from score -2.480355\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "Early stopping, best iteration is:\n",
            "[14]\ttraining's auc: 0.9696\ttraining's binary_logloss: 0.239778\tvalid_1's auc: 0.719107\tvalid_1's binary_logloss: 0.263888\n",
            "Fold 1 AUC: 0.71911\n",
            "\n",
            "========== Fold 2 ==========\n",
            "[LightGBM] [Info] Number of positive: 789, number of negative: 9425\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.388627 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 94440\n",
            "[LightGBM] [Info] Number of data points in the train set: 10214, number of used features: 500\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077247 -> initscore=-2.480355\n",
            "[LightGBM] [Info] Start training from score -2.480355\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "Early stopping, best iteration is:\n",
            "[14]\ttraining's auc: 0.96756\ttraining's binary_logloss: 0.240097\tvalid_1's auc: 0.719282\tvalid_1's binary_logloss: 0.264294\n",
            "Fold 2 AUC: 0.71928\n",
            "\n",
            "========== Fold 3 ==========\n",
            "[LightGBM] [Info] Number of positive: 790, number of negative: 9424\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.207610 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 94501\n",
            "[LightGBM] [Info] Number of data points in the train set: 10214, number of used features: 500\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077345 -> initscore=-2.478982\n",
            "[LightGBM] [Info] Start training from score -2.478982\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "Early stopping, best iteration is:\n",
            "[14]\ttraining's auc: 0.966636\ttraining's binary_logloss: 0.240831\tvalid_1's auc: 0.716507\tvalid_1's binary_logloss: 0.264252\n",
            "Fold 3 AUC: 0.71651\n",
            "\n",
            "========== Fold 4 ==========\n",
            "[LightGBM] [Info] Number of positive: 790, number of negative: 9425\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.273506 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 94460\n",
            "[LightGBM] [Info] Number of data points in the train set: 10215, number of used features: 500\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077337 -> initscore=-2.479088\n",
            "[LightGBM] [Info] Start training from score -2.479088\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "Early stopping, best iteration is:\n",
            "[12]\ttraining's auc: 0.96923\ttraining's binary_logloss: 0.243946\tvalid_1's auc: 0.758707\tvalid_1's binary_logloss: 0.261495\n",
            "Fold 4 AUC: 0.75871\n",
            "\n",
            "========== Fold 5 ==========\n",
            "[LightGBM] [Info] Number of positive: 790, number of negative: 9425\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219901 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 94421\n",
            "[LightGBM] [Info] Number of data points in the train set: 10215, number of used features: 500\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077337 -> initscore=-2.479088\n",
            "[LightGBM] [Info] Start training from score -2.479088\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "Early stopping, best iteration is:\n",
            "[17]\ttraining's auc: 0.972594\ttraining's binary_logloss: 0.238344\tvalid_1's auc: 0.752943\tvalid_1's binary_logloss: 0.261928\n",
            "Fold 5 AUC: 0.75294\n",
            "\n",
            "========== CV RESULT ==========\n",
            "Mean AUC : 0.733309\n",
            "Std  AUC : 0.018500\n"
          ]
        }
      ],
      "source": [
        "# hitung imbalance ratio\n",
        "pos_weight = (len(y) - y.sum()) / y.sum()\n",
        "\n",
        "gbm = lgb.LGBMClassifier(\n",
        "    n_estimators=10000,\n",
        "    learning_rate=0.01,\n",
        "    num_leaves=63,\n",
        "    max_depth=-1,\n",
        "    min_child_weight=1,\n",
        "    min_split_gain=0.0,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=0.1,\n",
        "    scale_pos_weight=pos_weight,\n",
        "    random_state=seed,\n",
        "    num_threads=cores\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# STRATIFIED K-FOLD\n",
        "# ================================\n",
        "\n",
        "folds = StratifiedKFold(\n",
        "    n_splits=num_folds,\n",
        "    shuffle=True,\n",
        "    random_state=seed\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# STORAGE\n",
        "# ================================\n",
        "\n",
        "valid_aucs_cv = np.zeros(num_folds)\n",
        "\n",
        "# ================================\n",
        "# CROSS-VALIDATION LOOP (TIDAK DIUBAH)\n",
        "# ================================\n",
        "\n",
        "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y)):\n",
        "\n",
        "    print(f\"\\n========== Fold {n_fold+1} ==========\")\n",
        "\n",
        "    # data partitioning\n",
        "    trn_x, trn_y = train[features].iloc[trn_idx], y.iloc[trn_idx]\n",
        "    val_x, val_y = train[features].iloc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "    # train lightGBM (OPERASI ASLI DIPERTAHANKAN)\n",
        "    gbm = gbm.fit(\n",
        "        trn_x,\n",
        "        trn_y,\n",
        "        eval_set=[(trn_x, trn_y), (val_x, val_y)],\n",
        "        eval_metric=metric,\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(stopping, verbose=True),\n",
        "            lgb.log_evaluation(period=verbose)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # validation AUC\n",
        "    val_pred = gbm.predict_proba(val_x)[:, 1]\n",
        "    valid_aucs_cv[n_fold] = roc_auc_score(val_y, val_pred)\n",
        "\n",
        "    print(f\"Fold {n_fold+1} AUC: {valid_aucs_cv[n_fold]:.5f}\")\n",
        "\n",
        "# ================================\n",
        "# CV RESULT\n",
        "# ================================\n",
        "\n",
        "print(\"\\n========== CV RESULT ==========\")\n",
        "print(f\"Mean AUC : {valid_aucs_cv.mean():.6f}\")\n",
        "print(f\"Std  AUC : {valid_aucs_cv.std():.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaRnxaZNmLYC"
      },
      "source": [
        "# 4. SUBMISSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "14xSn0GzmLYD"
      },
      "outputs": [],
      "source": [
        "# create submission\n",
        "test[\"TARGET\"] = test_preds_cv\n",
        "subm = test[[\"SK_ID_CURR\", \"TARGET\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "bfYnhivlmLYD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "347b431c-d9b8-4528-a006-3145195614fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved as submission_lgb.csv in current working directory\n"
          ]
        }
      ],
      "source": [
        "# hitung mean AUC sebagai pengganti 'auc'\n",
        "auc = valid_aucs_cv.mean()\n",
        "\n",
        "# simpan submission dengan nama sederhana\n",
        "filename = \"submission_lgb.csv\"\n",
        "\n",
        "subm.to_csv(filename, index=False, float_format=\"%.8f\")\n",
        "print(f\"File saved as {filename} in current working directory\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoM2DlypmLYE"
      },
      "outputs": [],
      "source": [
        "# no card, old features (560):            0.786941 | 0.783\n",
        "# no card, new features (694):            0.788893 | 0.783\n",
        "# with card, new features (1072):         0.790123 | 0.787\n",
        "# with card and kernel features (1109):   0.790053 |\n",
        "# card, kernel, factorize, no na (978):   0.790803 |\n",
        "# card, kern, fac, nona, adummy (1193):   0.791321 |\n",
        "# full data, one-hot ecoding (1844):      0.791850 |\n",
        "# full data, one-hot, extra sums (2486):  0.791880 | 0.789\n",
        "# full, one-hot, sums, buroscore (2501):  0.791761 |\n",
        "# full, one-hot, clean, buroscore (1826): 0.791867 |\n",
        "# last data + ext, age ratios (1828):     0.791808 |\n",
        "# new app feats, remove weighted (1830):  0.794241 | 0.795\n",
        "# previous data - top1000 LGB features:   0.794384 |\n",
        "# select top1500 LGB features:            0.794384 |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}